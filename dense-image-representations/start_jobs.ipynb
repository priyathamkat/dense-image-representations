{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scancel: error: Kill job error on job id 2562110: Access/permission denied\n",
      "scancel: error: Kill job error on job id 2562111: Access/permission denied\n",
      "scancel: error: Kill job error on job id 2562112: Access/permission denied\n",
      "scancel: error: Kill job error on job id 2562116: Access/permission denied\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "for i in range(2562091, 2562126):\n",
    "    subprocess.run([\"scancel\", str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip_edge_tokens/5e-05-4-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-05-4-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 54169 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 4 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-05-4-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564374\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip_edge_tokens/5e-05-6-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-05-6-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 8621 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-05-6-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564375\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip_edge_tokens/5e-05-8-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-05-8-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 60690 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 8 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-05-8-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564376\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-05\n",
      "#SBATCH --output results_clip_edge_tokens/1e-05-4-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-05-4-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 62691 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 4 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-05-4-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564377\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-05\n",
      "#SBATCH --output results_clip_edge_tokens/1e-05-6-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-05-6-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 46719 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-05-6-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564378\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-05\n",
      "#SBATCH --output results_clip_edge_tokens/1e-05-8-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-05-8-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 36006 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 8 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-05-8-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564379\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-06\n",
      "#SBATCH --output results_clip_edge_tokens/5e-06-4-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-06-4-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 2799 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 4 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-06-4-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564380\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-06\n",
      "#SBATCH --output results_clip_edge_tokens/5e-06-6-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-06-6-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 28715 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-06-6-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564381\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-06\n",
      "#SBATCH --output results_clip_edge_tokens/5e-06-8-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-06-8-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 3388 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 8 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-06-8-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564382\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-06\n",
      "#SBATCH --output results_clip_edge_tokens/1e-06-4-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-06-4-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 21527 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 4 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-06-4-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564383\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-06\n",
      "#SBATCH --output results_clip_edge_tokens/1e-06-6-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-06-6-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 5855 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-06-6-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564384\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-06\n",
      "#SBATCH --output results_clip_edge_tokens/1e-06-8-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-06-8-clip_preembed_attn_mask/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 30780 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 8 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-06-8-clip_preembed_attn_mask \\\n",
      "--use_attention_mask \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2564385\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from random import randrange \n",
    "import glob \n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_script.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "result_dir_name = 'results_clip_edge_tokens'\n",
    "\n",
    "batch_sizes = [256]\n",
    "lrs = [5e-5, 1e-5, 5e-6, 1e-6]\n",
    "projection_dims = [512]\n",
    "num_layerss = [4, 6, 8]\n",
    "num_headss = [8]\n",
    "epochss = [100]\n",
    "warmups = [10]\n",
    "validation_epochss = [5]\n",
    "preembed_nodess = [True]\n",
    "use_attention_mask = True\n",
    "text_encoders = ['clip']\n",
    "transformers = ['ours']\n",
    "\n",
    "\n",
    "exps = []\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_layers in num_layerss:\n",
    "            for num_heads in num_headss:\n",
    "                for epochs in epochss:\n",
    "                    for warmup in warmups:\n",
    "                        for validation_epochs in validation_epochss:\n",
    "                            for preembed_nodes in preembed_nodess:\n",
    "                                for text_encoder in text_encoders:\n",
    "                                    for transformer in transformers:\n",
    "                                        for projection_dim in projection_dims:\n",
    "                                            exp_name = f\"{lr}-{num_layers}-{text_encoder}{'_preembed' if preembed_nodes else ''}{'_attn_mask' if use_attention_mask else ''}\"\n",
    "                                            # exp_name = f\"{lr}-{text_encoder}{'_preembed' if preembed_nodes else ''}_clip_transformer_prelin\"\n",
    "                                            exps.append(exp_name)\n",
    "                                            \n",
    "                                            result_dir = f\"{result_dir_name}/{exp_name}\"\n",
    "                                            if not os.path.exists(result_dir):\n",
    "                                                os.makedirs(result_dir)\n",
    "\n",
    "                                            file = re.sub('--main_process_port .*', f\"--main_process_port {randrange(0, 65535)} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                            file = re.sub('--lr .*', f\"--lr {lr} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--batch_size .*', f\"--batch_size {batch_size} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--epochs .*', f\"--epochs {epochs} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--validation_epochs .*', f\"--validation_epochs {validation_epochs} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--warmup .*', f\"--warmup {warmup} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--num_heads .*', f\"--num_heads {num_heads} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--transformer .*', f\"--transformer {transformer} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--exp_name .*', f\"--exp_name {exp_name} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--result_dir .*', f\"--result_dir {result_dir_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                            file = re.sub('--job-name=.*', f\"--job-name={batch_size}{lr}\", file)\n",
    "                                            file = re.sub('--output .*', f\"--output {result_dir}/train.log\", file)\n",
    "                                            file = re.sub('--error .*', f\"--error {result_dir}/train.log\", file)\n",
    "\n",
    "                                            if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "                                                file += \"\\n--preembed_nodes \\\\\"\n",
    "                                            elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "                                                split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "                                                file = \"\".join(split)\n",
    "\n",
    "                                            if use_attention_mask and \"--use_attention_mask \\\\\" not in file:\n",
    "                                                file += \"\\n--use_attention_mask \\\\\"\n",
    "                                            elif use_attention_mask == False and \"--use_attention_mask \\\\\" in file:\n",
    "                                                split = file.split(\"\\n--use_attention_mask \\\\\")\n",
    "                                                file = \"\".join(split)\n",
    "\n",
    "                                            print(file)\n",
    "\n",
    "                                            with open(filename, 'w') as f:\n",
    "                                                f.write(file)\n",
    "\n",
    "                                            subprocess.run([\"sbatch\", filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-06\n",
      "#SBATCH --output results_clip_edge_tokens/1e-06-vit_s-clip_baseline/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-06-vit_s-clip_baseline/train.log\n",
      "#SBATCH --time=70:00:00\n",
      "#SBATCH --gres=gpu:rtxa6000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 56948 \\\n",
      "contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--lr 1e-06 \\\n",
      "--exp_name 1e-06-vit_s-clip_baseline \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "Submitted batch job 2597375\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-06\n",
      "#SBATCH --output results_clip_edge_tokens/5e-06-vit_s-clip_baseline/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-06-vit_s-clip_baseline/train.log\n",
      "#SBATCH --time=70:00:00\n",
      "#SBATCH --gres=gpu:rtxa6000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 44591 \\\n",
      "contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--lr 5e-06 \\\n",
      "--exp_name 5e-06-vit_s-clip_baseline \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "Submitted batch job 2597376\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip_edge_tokens/5e-05-vit_s-clip_baseline/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-05-vit_s-clip_baseline/train.log\n",
      "#SBATCH --time=70:00:00\n",
      "#SBATCH --gres=gpu:rtxa6000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 62744 \\\n",
      "contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--lr 5e-05 \\\n",
      "--exp_name 5e-05-vit_s-clip_baseline \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "Submitted batch job 2597377\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-05\n",
      "#SBATCH --output results_clip_edge_tokens/1e-05-vit_s-clip_baseline/train.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-05-vit_s-clip_baseline/train.log\n",
      "#SBATCH --time=70:00:00\n",
      "#SBATCH --gres=gpu:rtxa6000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 37789 \\\n",
      "contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--lr 1e-05 \\\n",
      "--exp_name 1e-05-vit_s-clip_baseline \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "Submitted batch job 2597378\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from random import randrange \n",
    "import glob \n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_base.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "result_dir_name = 'results_clip_edge_tokens'\n",
    "\n",
    "batch_sizes = [256]\n",
    "lrs = [1e-6, 5e-6, 5e-5, 1e-5]\n",
    "projection_dims = [512]\n",
    "epochss = [100]\n",
    "warmups = [10]\n",
    "validation_epochss = [5]\n",
    "checkpoint_epochs = 5\n",
    "image_encoders = ['vit_s']\n",
    "text_encoders = ['clip']\n",
    "\n",
    "\n",
    "exps = []\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for epochs in epochss:\n",
    "            for warmup in warmups:\n",
    "                for image_encoder in image_encoders:\n",
    "                    for text_encoder in text_encoders:\n",
    "                        for validation_epochs in validation_epochss:\n",
    "                            for projection_dim in projection_dims:\n",
    "                                exp_name = f\"{lr}-{image_encoder}-{text_encoder}_baseline\"\n",
    "                                exps.append(exp_name)\n",
    "                                \n",
    "                                result_dir = f\"{result_dir_name}/{exp_name}\"\n",
    "                                if not os.path.exists(result_dir):\n",
    "                                    os.makedirs(result_dir)\n",
    "\n",
    "                                file = re.sub('--main_process_port .*', f\"--main_process_port {randrange(0, 65535)} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                file = re.sub('--lr .*', f\"--lr {lr} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--batch_size .*', f\"--batch_size {batch_size} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--epochs .*', f\"--epochs {epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--validation_epochs .*', f\"--validation_epochs {validation_epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--checkpoint_epochs .*', f\"--checkpoint_epochs {checkpoint_epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--warmup .*', f\"--warmup {warmup} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--exp_name .*', f\"--exp_name {exp_name} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--result_dir .*', f\"--result_dir {result_dir_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                file = re.sub('--job-name=.*', f\"--job-name={batch_size}{lr}\", file)\n",
    "                                file = re.sub('--output .*', f\"--output {result_dir}/train.log\", file)\n",
    "                                file = re.sub('--error .*', f\"--error {result_dir}/train.log\", file)\n",
    "\n",
    "                                print(file) \n",
    "\n",
    "                                with open(filename, 'w') as f:\n",
    "                                    f.write(file)\n",
    "\n",
    "                                subprocess.run([\"sbatch\", filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip_edge_tokens/5e-06-vit_s-clip_baseline/aro_vgr.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-06-vit_s-clip_baseline/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 21164 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-06-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598430\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip_edge_tokens/5e-06-vit_s-clip_baseline/aro_vga.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-06-vit_s-clip_baseline/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 57398 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-06-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598431\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip_edge_tokens/5e-06-vit_s-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-06-vit_s-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 38771 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-06-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598432\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_flickr_order\n",
      "#SBATCH --output results_clip_edge_tokens/5e-06-vit_s-clip_baseline/aro_flickr_order.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-06-vit_s-clip_baseline/aro_flickr_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 29436 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_flickr_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-06-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598433\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip_edge_tokens/1e-05-vit_s-clip_baseline/aro_vgr.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-05-vit_s-clip_baseline/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 26251 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-05-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598434\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip_edge_tokens/1e-05-vit_s-clip_baseline/aro_vga.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-05-vit_s-clip_baseline/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 63617 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-05-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598435\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip_edge_tokens/1e-05-vit_s-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-05-vit_s-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 43855 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-05-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598436\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_flickr_order\n",
      "#SBATCH --output results_clip_edge_tokens/1e-05-vit_s-clip_baseline/aro_flickr_order.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-05-vit_s-clip_baseline/aro_flickr_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 46276 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_flickr_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-05-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598437\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip_edge_tokens/1e-06-vit_s-clip_baseline/aro_vgr.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-06-vit_s-clip_baseline/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 48657 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-06-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598438\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip_edge_tokens/1e-06-vit_s-clip_baseline/aro_vga.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-06-vit_s-clip_baseline/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 52866 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-06-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598439\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip_edge_tokens/1e-06-vit_s-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-06-vit_s-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 16320 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-06-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598440\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_flickr_order\n",
      "#SBATCH --output results_clip_edge_tokens/1e-06-vit_s-clip_baseline/aro_flickr_order.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-06-vit_s-clip_baseline/aro_flickr_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 27098 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_flickr_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 1e-06-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598441\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip_edge_tokens/5e-05-vit_s-clip_baseline/aro_vgr.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-05-vit_s-clip_baseline/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 12635 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-05-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598442\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip_edge_tokens/5e-05-vit_s-clip_baseline/aro_vga.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-05-vit_s-clip_baseline/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 49392 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-05-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598443\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip_edge_tokens/5e-05-vit_s-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-05-vit_s-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 39916 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-05-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598444\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_flickr_order\n",
      "#SBATCH --output results_clip_edge_tokens/5e-05-vit_s-clip_baseline/aro_flickr_order.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-05-vit_s-clip_baseline/aro_flickr_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 18838 \\\n",
      "aro_eval.py \\\n",
      "--dataset aro_flickr_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "--exp_name 5e-05-vit_s-clip_baseline \\\n",
      "Submitted batch job 2598445\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess \n",
    "import glob\n",
    "from random import randrange \n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_aro.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "result_dir_name = 'results_clip_edge_tokens'\n",
    "\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*_baseline')]\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*_clip_transformer_prelin')]\n",
    "# exps += [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*clip')]\n",
    "# exps += [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*preembed')]\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*vit-clip_baseline')]\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*vit_small-clip_baseline')]\n",
    "exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*vit_s-clip_baseline')]\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*_attn_mask')]\n",
    "# exps = ['5e-05-4-clip_preembed_attn_mask']\n",
    "# exps += ['5e-05-vit_pretrained-clip_baseline']\n",
    "\n",
    "projection_dim = 512\n",
    "image_encoder = 'vit_s'\n",
    "text_encoder = 'clip'\n",
    "num_layers = 8\n",
    "datasets = ['aro_vgr', 'aro_vga', 'aro_coco_order', 'aro_flickr_order']\n",
    "\n",
    "for exp in exps:\n",
    "    for dataset in datasets:\n",
    "        result_dir = f'{result_dir_name}/{exp}'\n",
    "\n",
    "        num_layers = re.findall(r'0\\d-(\\d+)-', exp)\n",
    "        if len(num_layers) > 0:\n",
    "            num_layers = num_layers[0]\n",
    "        else:\n",
    "            num_layers = 6\n",
    "        transformer = 'clip' if '_clip_transformer' in exp else 'ours'\n",
    "        preembed_nodes = '_preembed' in exp\n",
    "        use_attention_mask = '_attn_mask' in exp\n",
    "\n",
    "        file = re.sub('--main_process_port .*', f\"--main_process_port {randrange(0, 65535)} \" + r\"\\\\\" , file)\n",
    "\n",
    "        file = re.sub('--dataset .*', f\"--dataset {dataset} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--transformer .*', f\"--transformer {transformer} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--exp_name .*', f\"--exp_name {exp} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--result_dir .*', f\"--result_dir {result_dir_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "        file = re.sub('--job-name=.*', f\"--job-name={dataset}\", file)\n",
    "        file = re.sub('--output .*', f\"--output {result_dir}/{dataset}.log\", file)\n",
    "        file = re.sub('--error .*', f\"--error {result_dir}/{dataset}.log\", file)\n",
    "\n",
    "        if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "            file += \"\\n--preembed_nodes \\\\\"\n",
    "        elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "            split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "            file = \"\".join(split)\n",
    "\n",
    "        if use_attention_mask and \"--use_attention_mask \\\\\" not in file:\n",
    "            file += \"\\n--use_attention_mask \\\\\"\n",
    "        elif use_attention_mask == False and \"--use_attention_mask \\\\\" in file:\n",
    "            split = file.split(\"\\n--use_attention_mask \\\\\")\n",
    "            file = \"\".join(split)\n",
    "\n",
    "        print(file)\n",
    "\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(file)\n",
    "\n",
    "        subprocess.run([\"sbatch\", filename])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip_edge_tokens/5e-06-vit_s-clip_baseline/winoground.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-06-vit_s-clip_baseline/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 53036 \\\n",
      "winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-vit_s-clip_baseline \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "Submitted batch job 2598593\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip_edge_tokens/1e-05-vit_s-clip_baseline/winoground.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-05-vit_s-clip_baseline/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 15055 \\\n",
      "winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-vit_s-clip_baseline \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "Submitted batch job 2598595\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip_edge_tokens/1e-06-vit_s-clip_baseline/winoground.log\n",
      "#SBATCH --error results_clip_edge_tokens/1e-06-vit_s-clip_baseline/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 64234 \\\n",
      "winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-vit_s-clip_baseline \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "Submitted batch job 2598596\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip_edge_tokens/5e-05-vit_s-clip_baseline/winoground.log\n",
      "#SBATCH --error results_clip_edge_tokens/5e-05-vit_s-clip_baseline/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 28675 \\\n",
      "winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder vit_s \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-vit_s-clip_baseline \\\n",
      "--result_dir results_clip_edge_tokens \\\n",
      "Submitted batch job 2598597\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import glob\n",
    "from random import randrange \n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_winoground.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "result_dir_name = 'results_clip_edge_tokens'\n",
    "exps = [\n",
    "    # 'clip32-clip32_baseline',\n",
    "    # '1e-06-clip-clip_baseline',\n",
    "    # '5e-06-clip-clip_baseline',\n",
    "    # '1e-05-clip-clip_baseline',\n",
    "    # '4-clip',\n",
    "    # '4-clip_preembed',\n",
    "    # '6-clip',\n",
    "    # '6-clip_preembed',\n",
    "    # '8-clip',\n",
    "    # '8-clip_preembed',\n",
    "    # '5e-06-8-clip',\n",
    "    # '1e-06-8-clip',\n",
    "    # '1e-05-8-clip',\n",
    "    # '12-clip',\n",
    "    # '12-clip_preembed',\n",
    "]\n",
    "\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*_baseline')]\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*_clip_transformer_prelin')]\n",
    "# exps += [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*clip')]\n",
    "# exps += [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*preembed')]\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*12-clip')]\n",
    "# exps += [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*12-clip_preembed')]\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*vit-clip_baseline')]\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*_attn_mask')]\n",
    "# exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*vit_small-clip_baseline')]\n",
    "exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*vit_s-clip_baseline')]\n",
    "# exps += ['5e-05-vit_pretrained-clip_baseline']\n",
    "\n",
    "projection_dim = 512\n",
    "image_encoder = 'vit_s'\n",
    "text_encoder = 'clip'\n",
    "num_layers = 8\n",
    "\n",
    "for exp in exps:\n",
    "    result_dir = f'{result_dir_name}/{exp}'\n",
    "\n",
    "    num_layers = re.findall(r'-(\\d)-', exp)\n",
    "    if len(num_layers) > 0:\n",
    "        num_layers = num_layers[0]\n",
    "    else:\n",
    "        num_layers = 6\n",
    "    transformer = 'clip' if '_clip_transformer' in exp else 'ours'\n",
    "    preembed_nodes = '_preembed' in exp\n",
    "    use_attention_mask = '_attn_mask' in exp\n",
    "\n",
    "    file = re.sub('--main_process_port .*', f\"--main_process_port {randrange(0, 65535)} \" + r\"\\\\\" , file)\n",
    "    \n",
    "    file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--transformer .*', f\"--transformer {transformer} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--exp_name .*', f\"--exp_name {exp} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--result_dir .*', f\"--result_dir {result_dir_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "    file = re.sub('--job-name=.*', f\"--job-name=winoground\", file)\n",
    "    file = re.sub('--output .*', f\"--output {result_dir}/winoground.log\", file)\n",
    "    file = re.sub('--error .*', f\"--error {result_dir}/winoground.log\", file)\n",
    "\n",
    "    if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "        file += \"\\n--preembed_nodes \\\\\"\n",
    "    elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "        split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "        file = \"\".join(split)\n",
    "\n",
    "    if use_attention_mask and \"--use_attention_mask \\\\\" not in file:\n",
    "        file += \"\\n--use_attention_mask \\\\\"\n",
    "    elif use_attention_mask == False and \"--use_attention_mask \\\\\" in file:\n",
    "        split = file.split(\"\\n--use_attention_mask \\\\\")\n",
    "        file = \"\".join(split)\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(file)\n",
    "\n",
    "    subprocess.run([\"sbatch\", filename])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
