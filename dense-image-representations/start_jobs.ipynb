{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scancel: error: Kill job error on job id 2480788: Access/permission denied\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "for i in range(2480785, 2480794):\n",
    "    subprocess.run([\"scancel\", str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results/4-clip_preembed/train.log\n",
      "#SBATCH --error results/4-clip_preembed/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--vision_tokens_train coco_visual_tokens \\\n",
      "--text_tokens_train coco_text_tokens \\\n",
      "--vision_tokens_val coco_val_visual_tokens \\\n",
      "--text_tokens_val coco_val_text_tokens \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 4 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 4-clip_preembed \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2506085\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results/4-clip/train.log\n",
      "#SBATCH --error results/4-clip/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--vision_tokens_train coco_visual_tokens \\\n",
      "--text_tokens_train coco_text_tokens \\\n",
      "--vision_tokens_val coco_val_visual_tokens \\\n",
      "--text_tokens_val coco_val_text_tokens \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 4 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 4-clip \\\n",
      "Submitted batch job 2506086\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results/6-clip_preembed/train.log\n",
      "#SBATCH --error results/6-clip_preembed/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--vision_tokens_train coco_visual_tokens \\\n",
      "--text_tokens_train coco_text_tokens \\\n",
      "--vision_tokens_val coco_val_visual_tokens \\\n",
      "--text_tokens_val coco_val_text_tokens \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 6-clip_preembed \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2506087\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results/6-clip/train.log\n",
      "#SBATCH --error results/6-clip/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--vision_tokens_train coco_visual_tokens \\\n",
      "--text_tokens_train coco_text_tokens \\\n",
      "--vision_tokens_val coco_val_visual_tokens \\\n",
      "--text_tokens_val coco_val_text_tokens \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 6-clip \\\n",
      "Submitted batch job 2506088\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results/8-clip_preembed/train.log\n",
      "#SBATCH --error results/8-clip_preembed/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--vision_tokens_train coco_visual_tokens \\\n",
      "--text_tokens_train coco_text_tokens \\\n",
      "--vision_tokens_val coco_val_visual_tokens \\\n",
      "--text_tokens_val coco_val_text_tokens \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 8 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 8-clip_preembed \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2506089\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results/8-clip/train.log\n",
      "#SBATCH --error results/8-clip/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--vision_tokens_train coco_visual_tokens \\\n",
      "--text_tokens_train coco_text_tokens \\\n",
      "--vision_tokens_val coco_val_visual_tokens \\\n",
      "--text_tokens_val coco_val_text_tokens \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 8 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 8-clip \\\n",
      "Submitted batch job 2506090\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results/12-clip_preembed/train.log\n",
      "#SBATCH --error results/12-clip_preembed/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--vision_tokens_train coco_visual_tokens \\\n",
      "--text_tokens_train coco_text_tokens \\\n",
      "--vision_tokens_val coco_val_visual_tokens \\\n",
      "--text_tokens_val coco_val_text_tokens \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 12 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 12-clip_preembed \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2506091\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results/12-clip/train.log\n",
      "#SBATCH --error results/12-clip/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--vision_tokens_train coco_visual_tokens \\\n",
      "--text_tokens_train coco_text_tokens \\\n",
      "--vision_tokens_val coco_val_visual_tokens \\\n",
      "--text_tokens_val coco_val_text_tokens \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 12 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 12-clip \\\n",
      "Submitted batch job 2506092\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from random import randrange \n",
    "import glob \n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_script.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "\n",
    "batch_sizes = [256]\n",
    "lrs = [5e-5]\n",
    "projection_dims = [512]\n",
    "num_layerss = [4, 6, 8, 12]\n",
    "num_headss = [8]\n",
    "epochss = [100]\n",
    "warmups = [10]\n",
    "validation_epochss = [5]\n",
    "preembed_nodess = [True, False]\n",
    "text_encoders = ['clip']\n",
    "\n",
    "\n",
    "exps = []\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_layers in num_layerss:\n",
    "            for num_heads in num_headss:\n",
    "                for epochs in epochss:\n",
    "                    for warmup in warmups:\n",
    "                        for validation_epochs in validation_epochss:\n",
    "                            for preembed_nodes in preembed_nodess:\n",
    "                                for text_encoder in text_encoders:\n",
    "                                    for projection_dim in projection_dims:\n",
    "                                        exp_name = f\"{num_layers}-{text_encoder}{'_preembed' if preembed_nodes else ''}\"\n",
    "                                        exps.append(exp_name)\n",
    "                                        \n",
    "                                        result_dir = f\"results/{exp_name}\"\n",
    "                                        if not os.path.exists(result_dir):\n",
    "                                            os.makedirs(result_dir)\n",
    "\n",
    "                                        file = re.sub('--lr .*', f\"--lr {lr} \" + r\"\\\\\" , file)\n",
    "                                        file = re.sub('--batch_size .*', f\"--batch_size {batch_size} \" + r\"\\\\\" , file)\n",
    "                                        file = re.sub('--epochs .*', f\"--epochs {epochs} \" + r\"\\\\\" , file)\n",
    "                                        file = re.sub('--validation_epochs .*', f\"--validation_epochs {validation_epochs} \" + r\"\\\\\" , file)\n",
    "                                        file = re.sub('--warmup .*', f\"--warmup {warmup} \" + r\"\\\\\" , file)\n",
    "                                        file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "                                        file = re.sub('--num_heads .*', f\"--num_heads {num_heads} \" + r\"\\\\\" , file)\n",
    "                                        file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "                                        file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "                                        file = re.sub('--exp_name .*', f\"--exp_name {exp_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                        file = re.sub('--job-name=.*', f\"--job-name={batch_size}{lr}\", file)\n",
    "                                        file = re.sub('--output .*', f\"--output {result_dir}/train.log\", file)\n",
    "                                        file = re.sub('--error .*', f\"--error {result_dir}/train.log\", file)\n",
    "\n",
    "                                        if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "                                            file += \"\\n--preembed_nodes \\\\\"\n",
    "                                        elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "                                            split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "                                            file = \"\".join(split)\n",
    "\n",
    "                                        print(file)\n",
    "\n",
    "                                        with open(filename, 'w') as f:\n",
    "                                            f.write(file)\n",
    "\n",
    "                                        subprocess.run([\"sbatch\", filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results/clip-clip_baseline/train.log\n",
      "#SBATCH --error results/clip-clip_baseline/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=32G\n",
      "\n",
      "python3 contrastive_train_baseline.py \\\n",
      "--text_tokens_train coco_text_tokens \\\n",
      "--text_tokens_val coco_val_text_tokens \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--lr 5e-05 \\\n",
      "--exp_name clip-clip_baseline \\\n",
      "Submitted batch job 2508014\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from random import randrange \n",
    "import glob \n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_base.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "batch_sizes = [256]\n",
    "lrs = [5e-5]\n",
    "projection_dims = [512]\n",
    "epochss = [100]\n",
    "warmups = [10]\n",
    "validation_epochss = [5]\n",
    "image_encoders = ['clip']\n",
    "text_encoders = ['clip']\n",
    "\n",
    "\n",
    "exps = []\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for epochs in epochss:\n",
    "            for warmup in warmups:\n",
    "                for image_encoder in image_encoders:\n",
    "                    for text_encoder in text_encoders:\n",
    "                        for validation_epochs in validation_epochss:\n",
    "                            for projection_dim in projection_dims:\n",
    "                                exp_name = f\"{image_encoder}-{text_encoder}_baseline\"\n",
    "                                exps.append(exp_name)\n",
    "                                \n",
    "                                result_dir = f\"results/{exp_name}\"\n",
    "                                if not os.path.exists(result_dir):\n",
    "                                    os.makedirs(result_dir)\n",
    "\n",
    "                                file = re.sub('--lr .*', f\"--lr {lr} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--batch_size .*', f\"--batch_size {batch_size} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--epochs .*', f\"--epochs {epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--validation_epochs .*', f\"--validation_epochs {validation_epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--warmup .*', f\"--warmup {warmup} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--exp_name .*', f\"--exp_name {exp_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                file = re.sub('--job-name=.*', f\"--job-name={batch_size}{lr}\", file)\n",
    "                                file = re.sub('--output .*', f\"--output {result_dir}/train.log\", file)\n",
    "                                file = re.sub('--error .*', f\"--error {result_dir}/train.log\", file)\n",
    "\n",
    "                                print(file)\n",
    "\n",
    "                                with open(filename, 'w') as f:\n",
    "                                    f.write(file)\n",
    "\n",
    "                                subprocess.run([\"sbatch\", filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results/clip32-clip32_baseline/aro_vgr.log\n",
      "#SBATCH --error results/clip32-clip32_baseline/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name clip32-clip32_baseline \\\n",
      "Submitted batch job 2508709\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results/clip32-clip32_baseline/aro_vga.log\n",
      "#SBATCH --error results/clip32-clip32_baseline/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name clip32-clip32_baseline \\\n",
      "Submitted batch job 2508710\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results/clip32-clip32_baseline/aro_coco_order.log\n",
      "#SBATCH --error results/clip32-clip32_baseline/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name clip32-clip32_baseline \\\n",
      "Submitted batch job 2508711\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_aro.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "exps = [\n",
    "'clip32-clip32_baseline'\n",
    "]\n",
    "\n",
    "projection_dim = 512\n",
    "image_encoder = 'clip'\n",
    "text_encoder = 'clip'\n",
    "num_layers = 6\n",
    "datasets = ['aro_vgr', 'aro_vga', 'aro_coco_order']\n",
    "\n",
    "for exp in exps:\n",
    "    for dataset in datasets:\n",
    "        result_dir = f'results/{exp}'\n",
    "\n",
    "        file = re.sub('--dataset .*', f\"--dataset {dataset} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--exp_name .*', f\"--exp_name {exp} \" + r\"\\\\\" , file)\n",
    "\n",
    "        file = re.sub('--job-name=.*', f\"--job-name={dataset}\", file)\n",
    "        file = re.sub('--output .*', f\"--output {result_dir}/{dataset}.log\", file)\n",
    "        file = re.sub('--error .*', f\"--error {result_dir}/{dataset}.log\", file)\n",
    "\n",
    "        \n",
    "        preembed_nodes = '_preembed' in exp\n",
    "\n",
    "        if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "            file += \"\\n--preembed_nodes \\\\\"\n",
    "        elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "            split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "            file = \"\".join(split)\n",
    "\n",
    "        print(file)\n",
    "\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(file)\n",
    "\n",
    "        subprocess.run([\"sbatch\", filename])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results/clip32-clip32_baseline/winoground.log\n",
      "#SBATCH --error results/clip32-clip32_baseline/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name clip32-clip32_baseline \\\n",
      "Submitted batch job 2508616\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_winoground.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "exps = [\n",
    "'clip32-clip32_baseline'\n",
    "]\n",
    "\n",
    "projection_dim = 512\n",
    "image_encoder = 'clip'\n",
    "text_encoder = 'clip'\n",
    "num_layers = 6\n",
    "\n",
    "for exp in exps:\n",
    "    result_dir = f'results/{exp}'\n",
    "\n",
    "    file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--exp_name .*', f\"--exp_name {exp} \" + r\"\\\\\" , file)\n",
    "\n",
    "    file = re.sub('--job-name=.*', f\"--job-name=winoground\", file)\n",
    "    file = re.sub('--output .*', f\"--output {result_dir}/winoground.log\", file)\n",
    "    file = re.sub('--error .*', f\"--error {result_dir}/winoground.log\", file)\n",
    "\n",
    "    \n",
    "    preembed_nodes = '_preembed' in exp\n",
    "\n",
    "    if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "        file += \"\\n--preembed_nodes \\\\\"\n",
    "    elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "        split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "        file = \"\".join(split)\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(file)\n",
    "\n",
    "    subprocess.run([\"sbatch\", filename])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
