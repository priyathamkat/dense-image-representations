{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scancel: error: Kill job error on job id 2541361: Access/permission denied\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "for i in range(2541347, 2541362):\n",
    "    subprocess.run([\"scancel\", str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip32/5e-05-12-clip_preembed/train.log\n",
      "#SBATCH --error results_clip32/5e-05-12-clip_preembed/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 9739 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 12 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip32 \\\n",
      "--exp_name 5e-05-12-clip_preembed \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2542550\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip32/5e-05-12-clip/train.log\n",
      "#SBATCH --error results_clip32/5e-05-12-clip/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "accelerate launch --multi_gpu \\\n",
      "--main_process_port 17320 \\\n",
      "contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 12 \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--result_dir results_clip32 \\\n",
      "--exp_name 5e-05-12-clip \\\n",
      "Submitted batch job 2542551\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from random import randrange \n",
    "import glob \n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_script.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "result_dir_name = 'results_clip32'\n",
    "\n",
    "batch_sizes = [256]\n",
    "lrs = [5e-5]\n",
    "projection_dims = [512]\n",
    "num_layerss = [12]\n",
    "num_headss = [8]\n",
    "epochss = [100]\n",
    "warmups = [10]\n",
    "validation_epochss = [5]\n",
    "preembed_nodess = [True, False]\n",
    "text_encoders = ['clip']\n",
    "transformers = ['ours']\n",
    "\n",
    "\n",
    "exps = []\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_layers in num_layerss:\n",
    "            for num_heads in num_headss:\n",
    "                for epochs in epochss:\n",
    "                    for warmup in warmups:\n",
    "                        for validation_epochs in validation_epochss:\n",
    "                            for preembed_nodes in preembed_nodess:\n",
    "                                for text_encoder in text_encoders:\n",
    "                                    for transformer in transformers:\n",
    "                                        for projection_dim in projection_dims:\n",
    "                                            exp_name = f\"{lr}-{num_layers}-{text_encoder}{'_preembed' if preembed_nodes else ''}\"\n",
    "                                            # exp_name = f\"{lr}-{text_encoder}{'_preembed' if preembed_nodes else ''}_clip_transformer_prelin\"\n",
    "                                            exps.append(exp_name)\n",
    "                                            \n",
    "                                            result_dir = f\"{result_dir_name}/{exp_name}\"\n",
    "                                            if not os.path.exists(result_dir):\n",
    "                                                os.makedirs(result_dir)\n",
    "\n",
    "                                            file = re.sub('--main_process_port .*', f\"--main_process_port {randrange(0, 65535)} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                            file = re.sub('--lr .*', f\"--lr {lr} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--batch_size .*', f\"--batch_size {batch_size} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--epochs .*', f\"--epochs {epochs} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--validation_epochs .*', f\"--validation_epochs {validation_epochs} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--warmup .*', f\"--warmup {warmup} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--num_heads .*', f\"--num_heads {num_heads} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--transformer .*', f\"--transformer {transformer} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--exp_name .*', f\"--exp_name {exp_name} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--result_dir .*', f\"--result_dir {result_dir_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                            file = re.sub('--job-name=.*', f\"--job-name={batch_size}{lr}\", file)\n",
    "                                            file = re.sub('--output .*', f\"--output {result_dir}/train.log\", file)\n",
    "                                            file = re.sub('--error .*', f\"--error {result_dir}/train.log\", file)\n",
    "\n",
    "                                            if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "                                                file += \"\\n--preembed_nodes \\\\\"\n",
    "                                            elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "                                                split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "                                                file = \"\".join(split)\n",
    "\n",
    "                                            print(file)\n",
    "\n",
    "                                            with open(filename, 'w') as f:\n",
    "                                                f.write(file)\n",
    "\n",
    "                                            subprocess.run([\"sbatch\", filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-05\n",
      "#SBATCH --output results_clip32/1e-05-clip-clip_baseline/train.log\n",
      "#SBATCH --error results_clip32/1e-05-clip-clip_baseline/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=32G\n",
      "\n",
      "python3 contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--lr 1e-05 \\\n",
      "--exp_name 1e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2518688\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip32/5e-05-clip-clip_baseline/train.log\n",
      "#SBATCH --error results_clip32/5e-05-clip-clip_baseline/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=32G\n",
      "\n",
      "python3 contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--lr 5e-05 \\\n",
      "--exp_name 5e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2518689\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-06\n",
      "#SBATCH --output results_clip32/5e-06-clip-clip_baseline/train.log\n",
      "#SBATCH --error results_clip32/5e-06-clip-clip_baseline/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=32G\n",
      "\n",
      "python3 contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--lr 5e-06 \\\n",
      "--exp_name 5e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2518690\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-06\n",
      "#SBATCH --output results_clip32/1e-06-clip-clip_baseline/train.log\n",
      "#SBATCH --error results_clip32/1e-06-clip-clip_baseline/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=32G\n",
      "\n",
      "python3 contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--lr 1e-06 \\\n",
      "--exp_name 1e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2518691\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from random import randrange \n",
    "import glob \n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_base.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "result_dir_name = 'results_clip32'\n",
    "\n",
    "batch_sizes = [256]\n",
    "lrs = [1e-5, 5e-5, 5e-6, 1e-6]\n",
    "projection_dims = [512]\n",
    "epochss = [100]\n",
    "warmups = [10]\n",
    "validation_epochss = [5]\n",
    "checkpoint_epochs = 5\n",
    "image_encoders = ['clip']\n",
    "text_encoders = ['clip']\n",
    "\n",
    "\n",
    "exps = []\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for epochs in epochss:\n",
    "            for warmup in warmups:\n",
    "                for image_encoder in image_encoders:\n",
    "                    for text_encoder in text_encoders:\n",
    "                        for validation_epochs in validation_epochss:\n",
    "                            for projection_dim in projection_dims:\n",
    "                                exp_name = f\"{lr}-{image_encoder}-{text_encoder}_baseline\"\n",
    "                                exps.append(exp_name)\n",
    "                                \n",
    "                                result_dir = f\"{result_dir_name}/{exp_name}\"\n",
    "                                if not os.path.exists(result_dir):\n",
    "                                    os.makedirs(result_dir)\n",
    "\n",
    "                                file = re.sub('--lr .*', f\"--lr {lr} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--batch_size .*', f\"--batch_size {batch_size} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--epochs .*', f\"--epochs {epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--validation_epochs .*', f\"--validation_epochs {validation_epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--checkpoint_epochs .*', f\"--checkpoint_epochs {checkpoint_epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--warmup .*', f\"--warmup {warmup} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--exp_name .*', f\"--exp_name {exp_name} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--result_dir .*', f\"--result_dir {result_dir_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                file = re.sub('--job-name=.*', f\"--job-name={batch_size}{lr}\", file)\n",
    "                                file = re.sub('--output .*', f\"--output {result_dir}/train.log\", file)\n",
    "                                file = re.sub('--error .*', f\"--error {result_dir}/train.log\", file)\n",
    "\n",
    "                                print(file)\n",
    "\n",
    "                                with open(filename, 'w') as f:\n",
    "                                    f.write(file)\n",
    "\n",
    "                                subprocess.run([\"sbatch\", filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/5e-06-clip_preembed_clip_transformer/aro_vgr.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_preembed_clip_transformer/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2529993\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/5e-06-clip_preembed_clip_transformer/aro_vga.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_preembed_clip_transformer/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2529994\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/5e-06-clip_preembed_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_preembed_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2529995\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/1e-06-clip_preembed_clip_transformer/aro_vgr.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_preembed_clip_transformer/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2529996\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/1e-06-clip_preembed_clip_transformer/aro_vga.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_preembed_clip_transformer/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2529997\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/1e-06-clip_preembed_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_preembed_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2529998\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/5e-05-clip_preembed_clip_transformer/aro_vgr.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_preembed_clip_transformer/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2529999\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/5e-05-clip_preembed_clip_transformer/aro_vga.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_preembed_clip_transformer/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2530000\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/5e-05-clip_preembed_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_preembed_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2530001\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/1e-06-clip_clip_transformer/aro_vgr.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_clip_transformer/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2530002\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/1e-06-clip_clip_transformer/aro_vga.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_clip_transformer/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2530003\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/1e-06-clip_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2530004\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/5e-06-clip_clip_transformer/aro_vgr.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_clip_transformer/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2530005\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/5e-06-clip_clip_transformer/aro_vga.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_clip_transformer/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2530006\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/5e-06-clip_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2530007\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/1e-05-clip_preembed_clip_transformer/aro_vgr.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_preembed_clip_transformer/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2530008\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/1e-05-clip_preembed_clip_transformer/aro_vga.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_preembed_clip_transformer/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2530009\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/1e-05-clip_preembed_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_preembed_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2530010\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/5e-05-clip_clip_transformer/aro_vgr.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_clip_transformer/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2530011\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/5e-05-clip_clip_transformer/aro_vga.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_clip_transformer/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2530012\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/5e-05-clip_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2530013\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/1e-05-clip_clip_transformer/aro_vgr.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_clip_transformer/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2530014\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/1e-05-clip_clip_transformer/aro_vga.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_clip_transformer/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2530015\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/1e-05-clip_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_clip_transformer/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2530016\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/5e-05-clip-clip_baseline/aro_vgr.log\n",
      "#SBATCH --error results_clip32/5e-05-clip-clip_baseline/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2530017\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/5e-05-clip-clip_baseline/aro_vga.log\n",
      "#SBATCH --error results_clip32/5e-05-clip-clip_baseline/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2530018\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/5e-05-clip-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/5e-05-clip-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2530019\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/1e-05-clip-clip_baseline/aro_vgr.log\n",
      "#SBATCH --error results_clip32/1e-05-clip-clip_baseline/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2530020\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/1e-05-clip-clip_baseline/aro_vga.log\n",
      "#SBATCH --error results_clip32/1e-05-clip-clip_baseline/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2530021\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/1e-05-clip-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/1e-05-clip-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2530022\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/5e-06-clip-clip_baseline/aro_vgr.log\n",
      "#SBATCH --error results_clip32/5e-06-clip-clip_baseline/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2530023\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/5e-06-clip-clip_baseline/aro_vga.log\n",
      "#SBATCH --error results_clip32/5e-06-clip-clip_baseline/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2530024\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/5e-06-clip-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/5e-06-clip-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2530025\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results_clip32/1e-06-clip-clip_baseline/aro_vgr.log\n",
      "#SBATCH --error results_clip32/1e-06-clip-clip_baseline/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2530026\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results_clip32/1e-06-clip-clip_baseline/aro_vga.log\n",
      "#SBATCH --error results_clip32/1e-06-clip-clip_baseline/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2530027\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results_clip32/1e-06-clip-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --error results_clip32/1e-06-clip-clip_baseline/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2530029\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_aro.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "result_dir_name = 'results_clip32'\n",
    "exps = [\n",
    "    # 'clip32-clip32_baseline',\n",
    "    # '1e-06-clip-clip_baseline',\n",
    "    # '5e-06-clip-clip_baseline',\n",
    "    # '1e-05-clip-clip_baseline',\n",
    "    # '4-clip',\n",
    "    # '4-clip_preembed',\n",
    "    # '6-clip',\n",
    "    # '6-clip_preembed',\n",
    "    # '8-clip',\n",
    "    # '8-clip_preembed',\n",
    "    # '5e-06-8-clip',\n",
    "    # '1e-06-8-clip',\n",
    "    # '1e-05-8-clip',\n",
    "    # '12-clip',\n",
    "    # '12-clip_preembed',\n",
    "]\n",
    "\n",
    "exps = [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*_clip_transformer')]\n",
    "exps += [f.split('/')[1] for f in glob.glob(f'{result_dir_name}/*_baseline')]\n",
    "\n",
    "projection_dim = 512\n",
    "image_encoder = 'clip'\n",
    "text_encoder = 'clip'\n",
    "num_layers = 8\n",
    "datasets = ['aro_vgr', 'aro_vga', 'aro_coco_order']\n",
    "\n",
    "for exp in exps:\n",
    "    for dataset in datasets:\n",
    "        result_dir = f'{result_dir_name}/{exp}'\n",
    "\n",
    "        num_layers = re.findall(r'-(\\d)-', exp)\n",
    "        if len(num_layers) > 0:\n",
    "            num_layers = num_layers[0]\n",
    "        else:\n",
    "            num_layers = 6\n",
    "        transformer = 'clip' if '_clip_transformer' in exp else 'ours'\n",
    "        preembed_nodes = '_preembed' in exp\n",
    "\n",
    "\n",
    "        file = re.sub('--dataset .*', f\"--dataset {dataset} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--transformer .*', f\"--transformer {transformer} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--exp_name .*', f\"--exp_name {exp} \" + r\"\\\\\" , file)\n",
    "\n",
    "        file = re.sub('--job-name=.*', f\"--job-name={dataset}\", file)\n",
    "        file = re.sub('--output .*', f\"--output {result_dir}/{dataset}.log\", file)\n",
    "        file = re.sub('--error .*', f\"--error {result_dir}/{dataset}.log\", file)\n",
    "\n",
    "        if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "            file += \"\\n--preembed_nodes \\\\\"\n",
    "        elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "            split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "            file = \"\".join(split)\n",
    "\n",
    "        print(file)\n",
    "\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(file)\n",
    "\n",
    "        subprocess.run([\"sbatch\", filename])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/5e-06-clip_preembed_clip_transformer/winoground.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_preembed_clip_transformer/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2530180\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/1e-06-clip_preembed_clip_transformer/winoground.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_preembed_clip_transformer/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2530181\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/5e-05-clip_preembed_clip_transformer/winoground.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_preembed_clip_transformer/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2530182\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/1e-06-clip_clip_transformer/winoground.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_clip_transformer/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2530183\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/5e-06-clip_clip_transformer/winoground.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_clip_transformer/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2530184\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/1e-05-clip_preembed_clip_transformer/winoground.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_preembed_clip_transformer/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2530185\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/5e-05-clip_clip_transformer/winoground.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_clip_transformer/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2530186\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/1e-05-clip_clip_transformer/winoground.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_clip_transformer/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer clip \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2530187\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/5e-05-clip-clip_baseline/winoground.log\n",
      "#SBATCH --error results_clip32/5e-05-clip-clip_baseline/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2530188\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/1e-05-clip-clip_baseline/winoground.log\n",
      "#SBATCH --error results_clip32/1e-05-clip-clip_baseline/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2530189\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/5e-06-clip-clip_baseline/winoground.log\n",
      "#SBATCH --error results_clip32/5e-06-clip-clip_baseline/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 5e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2530190\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results_clip32/1e-06-clip-clip_baseline/winoground.log\n",
      "#SBATCH --error results_clip32/1e-06-clip-clip_baseline/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--transformer ours \\\n",
      "--num_layers 6 \\\n",
      "--exp_name 1e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2530191\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_winoground.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "result_dir_name = 'results_clip32'\n",
    "exps = [\n",
    "    # 'clip32-clip32_baseline',\n",
    "    # '1e-06-clip-clip_baseline',\n",
    "    # '5e-06-clip-clip_baseline',\n",
    "    # '1e-05-clip-clip_baseline',\n",
    "    # '4-clip',\n",
    "    # '4-clip_preembed',\n",
    "    # '6-clip',\n",
    "    # '6-clip_preembed',\n",
    "    # '8-clip',\n",
    "    # '8-clip_preembed',\n",
    "    # '5e-06-8-clip',\n",
    "    # '1e-06-8-clip',\n",
    "    # '1e-05-8-clip',\n",
    "    # '12-clip',\n",
    "    # '12-clip_preembed',\n",
    "]\n",
    "\n",
    "exps = [f.split('/')[1] for f in glob.glob('results_clip32/*_clip_transformer')]\n",
    "exps += [f.split('/')[1] for f in glob.glob('results_clip32/*_baseline')]\n",
    "\n",
    "projection_dim = 512\n",
    "image_encoder = 'clip'\n",
    "text_encoder = 'clip'\n",
    "num_layers = 8\n",
    "\n",
    "for exp in exps:\n",
    "    result_dir = f'{result_dir_name}/{exp}'\n",
    "\n",
    "    num_layers = re.findall(r'-(\\d)-', exp)\n",
    "    if len(num_layers) > 0:\n",
    "        num_layers = num_layers[0]\n",
    "    else:\n",
    "        num_layers = 6\n",
    "    transformer = 'clip' if '_clip_transformer' in exp else 'ours'\n",
    "    preembed_nodes = '_preembed' in exp\n",
    "\n",
    "\n",
    "    file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--transformer .*', f\"--transformer {transformer} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--exp_name .*', f\"--exp_name {exp} \" + r\"\\\\\" , file)\n",
    "\n",
    "    file = re.sub('--job-name=.*', f\"--job-name=winoground\", file)\n",
    "    file = re.sub('--output .*', f\"--output {result_dir}/winoground.log\", file)\n",
    "    file = re.sub('--error .*', f\"--error {result_dir}/winoground.log\", file)\n",
    "\n",
    "    if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "        file += \"\\n--preembed_nodes \\\\\"\n",
    "    elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "        split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "        file = \"\".join(split)\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(file)\n",
    "\n",
    "    subprocess.run([\"sbatch\", filename])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
