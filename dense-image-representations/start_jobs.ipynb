{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scancel: error: Kill job error on job id 2518182: Access/permission denied\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "for i in range(2518171, 2518186):\n",
    "    subprocess.run([\"scancel\", str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-05\n",
      "#SBATCH --output results_clip32/1e-05-clip_preembed_clip_transformer/train.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_preembed_clip_transformer/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 1e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2518989\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-05\n",
      "#SBATCH --output results_clip32/1e-05-clip_clip_transformer/train.log\n",
      "#SBATCH --error results_clip32/1e-05-clip_clip_transformer/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 1e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2518990\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip32/5e-05-clip_preembed_clip_transformer/train.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_preembed_clip_transformer/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 5e-05-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2518991\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip32/5e-05-clip_clip_transformer/train.log\n",
      "#SBATCH --error results_clip32/5e-05-clip_clip_transformer/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-05 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 5e-05-clip_clip_transformer \\\n",
      "Submitted batch job 2518992\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-06\n",
      "#SBATCH --output results_clip32/5e-06-clip_preembed_clip_transformer/train.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_preembed_clip_transformer/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 5e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2518993\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-06\n",
      "#SBATCH --output results_clip32/5e-06-clip_clip_transformer/train.log\n",
      "#SBATCH --error results_clip32/5e-06-clip_clip_transformer/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 5e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 5e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2518994\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-06\n",
      "#SBATCH --output results_clip32/1e-06-clip_preembed_clip_transformer/train.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_preembed_clip_transformer/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 1e-06-clip_preembed_clip_transformer \\\n",
      "--preembed_nodes \\\n",
      "Submitted batch job 2518995\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-06\n",
      "#SBATCH --output results_clip32/1e-06-clip_clip_transformer/train.log\n",
      "#SBATCH --error results_clip32/1e-06-clip_clip_transformer/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:2\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "python3 contrastive_train.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 20 \\\n",
      "--projection_dim 512 \\\n",
      "--lr 1e-06 \\\n",
      "--num_heads 8 \\\n",
      "--num_layers 6 \\\n",
      "--text_encoder clip \\\n",
      "--exp_name 1e-06-clip_clip_transformer \\\n",
      "Submitted batch job 2518996\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from random import randrange \n",
    "import glob \n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_script.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "\n",
    "batch_sizes = [256]\n",
    "lrs = [1e-5, 5e-5, 5e-6, 1e-6]\n",
    "projection_dims = [512]\n",
    "num_layerss = [6]\n",
    "num_headss = [8]\n",
    "epochss = [100]\n",
    "warmups = [10]\n",
    "validation_epochss = [5]\n",
    "preembed_nodess = [True, False]\n",
    "text_encoders = ['clip']\n",
    "transformers = ['clip']\n",
    "\n",
    "\n",
    "exps = []\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_layers in num_layerss:\n",
    "            for num_heads in num_headss:\n",
    "                for epochs in epochss:\n",
    "                    for warmup in warmups:\n",
    "                        for validation_epochs in validation_epochss:\n",
    "                            for preembed_nodes in preembed_nodess:\n",
    "                                for text_encoder in text_encoders:\n",
    "                                    for transformer in transformers:\n",
    "                                        for projection_dim in projection_dims:\n",
    "                                            # exp_name = f\"{lr}-{num_layers}-{text_encoder}{'_preembed' if preembed_nodes else ''}\"\n",
    "                                            exp_name = f\"{lr}-{text_encoder}{'_preembed' if preembed_nodes else ''}_clip_transformer\"\n",
    "                                            exps.append(exp_name)\n",
    "                                            \n",
    "                                            result_dir = f\"results_clip32/{exp_name}\"\n",
    "                                            if not os.path.exists(result_dir):\n",
    "                                                os.makedirs(result_dir)\n",
    "\n",
    "                                            file = re.sub('--lr .*', f\"--lr {lr} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--batch_size .*', f\"--batch_size {batch_size} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--epochs .*', f\"--epochs {epochs} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--validation_epochs .*', f\"--validation_epochs {validation_epochs} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--warmup .*', f\"--warmup {warmup} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--num_heads .*', f\"--num_heads {num_heads} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--transformer .*', f\"--transformer {transformer} \" + r\"\\\\\" , file)\n",
    "                                            file = re.sub('--exp_name .*', f\"--exp_name {exp_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                            file = re.sub('--job-name=.*', f\"--job-name={batch_size}{lr}\", file)\n",
    "                                            file = re.sub('--output .*', f\"--output {result_dir}/train.log\", file)\n",
    "                                            file = re.sub('--error .*', f\"--error {result_dir}/train.log\", file)\n",
    "\n",
    "                                            if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "                                                file += \"\\n--preembed_nodes \\\\\"\n",
    "                                            elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "                                                split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "                                                file = \"\".join(split)\n",
    "\n",
    "                                            print(file)\n",
    "\n",
    "                                            with open(filename, 'w') as f:\n",
    "                                                f.write(file)\n",
    "\n",
    "                                            subprocess.run([\"sbatch\", filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-05\n",
      "#SBATCH --output results_clip32/1e-05-clip-clip_baseline/train.log\n",
      "#SBATCH --error results_clip32/1e-05-clip-clip_baseline/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=32G\n",
      "\n",
      "python3 contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--lr 1e-05 \\\n",
      "--exp_name 1e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2518688\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-05\n",
      "#SBATCH --output results_clip32/5e-05-clip-clip_baseline/train.log\n",
      "#SBATCH --error results_clip32/5e-05-clip-clip_baseline/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=32G\n",
      "\n",
      "python3 contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--lr 5e-05 \\\n",
      "--exp_name 5e-05-clip-clip_baseline \\\n",
      "Submitted batch job 2518689\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2565e-06\n",
      "#SBATCH --output results_clip32/5e-06-clip-clip_baseline/train.log\n",
      "#SBATCH --error results_clip32/5e-06-clip-clip_baseline/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=32G\n",
      "\n",
      "python3 contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--lr 5e-06 \\\n",
      "--exp_name 5e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2518690\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=2561e-06\n",
      "#SBATCH --output results_clip32/1e-06-clip-clip_baseline/train.log\n",
      "#SBATCH --error results_clip32/1e-06-clip-clip_baseline/train.log\n",
      "#SBATCH --time=71:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:4\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=32G\n",
      "\n",
      "python3 contrastive_train_baseline.py \\\n",
      "--dataset coco \\\n",
      "--batch_size 256 \\\n",
      "--epochs 100 \\\n",
      "--warmup 10 \\\n",
      "--validation_epochs 5 \\\n",
      "--checkpoint_epochs 5 \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--lr 1e-06 \\\n",
      "--exp_name 1e-06-clip-clip_baseline \\\n",
      "Submitted batch job 2518691\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from random import randrange \n",
    "import glob \n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_base.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "batch_sizes = [256]\n",
    "lrs = [1e-5, 5e-5, 5e-6, 1e-6]\n",
    "projection_dims = [512]\n",
    "epochss = [100]\n",
    "warmups = [10]\n",
    "validation_epochss = [5]\n",
    "checkpoint_epochs = 5\n",
    "image_encoders = ['clip']\n",
    "text_encoders = ['clip']\n",
    "\n",
    "\n",
    "exps = []\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for epochs in epochss:\n",
    "            for warmup in warmups:\n",
    "                for image_encoder in image_encoders:\n",
    "                    for text_encoder in text_encoders:\n",
    "                        for validation_epochs in validation_epochss:\n",
    "                            for projection_dim in projection_dims:\n",
    "                                exp_name = f\"{lr}-{image_encoder}-{text_encoder}_baseline\"\n",
    "                                exps.append(exp_name)\n",
    "                                \n",
    "                                result_dir = f\"results_clip32/{exp_name}\"\n",
    "                                if not os.path.exists(result_dir):\n",
    "                                    os.makedirs(result_dir)\n",
    "\n",
    "                                file = re.sub('--lr .*', f\"--lr {lr} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--batch_size .*', f\"--batch_size {batch_size} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--epochs .*', f\"--epochs {epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--validation_epochs .*', f\"--validation_epochs {validation_epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--checkpoint_epochs .*', f\"--checkpoint_epochs {checkpoint_epochs} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--warmup .*', f\"--warmup {warmup} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "                                file = re.sub('--exp_name .*', f\"--exp_name {exp_name} \" + r\"\\\\\" , file)\n",
    "\n",
    "                                file = re.sub('--job-name=.*', f\"--job-name={batch_size}{lr}\", file)\n",
    "                                file = re.sub('--output .*', f\"--output {result_dir}/train.log\", file)\n",
    "                                file = re.sub('--error .*', f\"--error {result_dir}/train.log\", file)\n",
    "\n",
    "                                print(file)\n",
    "\n",
    "                                with open(filename, 'w') as f:\n",
    "                                    f.write(file)\n",
    "\n",
    "                                subprocess.run([\"sbatch\", filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results/5e-06-8-clip/aro_vgr.log\n",
      "#SBATCH --error results/5e-06-8-clip/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 5e-06-8-clip \\\n",
      "Submitted batch job 2514037\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results/5e-06-8-clip/aro_vga.log\n",
      "#SBATCH --error results/5e-06-8-clip/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 5e-06-8-clip \\\n",
      "Submitted batch job 2514038\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results/5e-06-8-clip/aro_coco_order.log\n",
      "#SBATCH --error results/5e-06-8-clip/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 5e-06-8-clip \\\n",
      "Submitted batch job 2514039\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results/1e-06-8-clip/aro_vgr.log\n",
      "#SBATCH --error results/1e-06-8-clip/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 1e-06-8-clip \\\n",
      "Submitted batch job 2514040\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results/1e-06-8-clip/aro_vga.log\n",
      "#SBATCH --error results/1e-06-8-clip/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 1e-06-8-clip \\\n",
      "Submitted batch job 2514041\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results/1e-06-8-clip/aro_coco_order.log\n",
      "#SBATCH --error results/1e-06-8-clip/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 1e-06-8-clip \\\n",
      "Submitted batch job 2514042\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vgr\n",
      "#SBATCH --output results/1e-05-8-clip/aro_vgr.log\n",
      "#SBATCH --error results/1e-05-8-clip/aro_vgr.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vgr \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 1e-05-8-clip \\\n",
      "Submitted batch job 2514043\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_vga\n",
      "#SBATCH --output results/1e-05-8-clip/aro_vga.log\n",
      "#SBATCH --error results/1e-05-8-clip/aro_vga.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_vga \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 1e-05-8-clip \\\n",
      "Submitted batch job 2514044\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=aro_coco_order\n",
      "#SBATCH --output results/1e-05-8-clip/aro_coco_order.log\n",
      "#SBATCH --error results/1e-05-8-clip/aro_coco_order.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 aro_eval.py \\\n",
      "--dataset aro_coco_order \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 1e-05-8-clip \\\n",
      "Submitted batch job 2514045\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_aro.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "exps = [\n",
    "    # 'clip32-clip32_baseline',\n",
    "    # '1e-06-clip-clip_baseline',\n",
    "    # '5e-06-clip-clip_baseline',\n",
    "    # '1e-05-clip-clip_baseline',\n",
    "    # '4-clip',\n",
    "    # '4-clip_preembed',\n",
    "    # '6-clip',\n",
    "    # '6-clip_preembed',\n",
    "    # '8-clip',\n",
    "    # '8-clip_preembed',\n",
    "    # '5e-06-8-clip',\n",
    "    # '1e-06-8-clip',\n",
    "    # '1e-05-8-clip',\n",
    "    # '12-clip',\n",
    "    # '12-clip_preembed',\n",
    "]\n",
    "\n",
    "projection_dim = 512\n",
    "image_encoder = 'clip'\n",
    "text_encoder = 'clip'\n",
    "num_layers = 8\n",
    "datasets = ['aro_vgr', 'aro_vga', 'aro_coco_order']\n",
    "\n",
    "for exp in exps:\n",
    "    for dataset in datasets:\n",
    "        result_dir = f'results/{exp}'\n",
    "\n",
    "        file = re.sub('--dataset .*', f\"--dataset {dataset} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "        file = re.sub('--exp_name .*', f\"--exp_name {exp} \" + r\"\\\\\" , file)\n",
    "\n",
    "        file = re.sub('--job-name=.*', f\"--job-name={dataset}\", file)\n",
    "        file = re.sub('--output .*', f\"--output {result_dir}/{dataset}.log\", file)\n",
    "        file = re.sub('--error .*', f\"--error {result_dir}/{dataset}.log\", file)\n",
    "\n",
    "        \n",
    "        preembed_nodes = '_preembed' in exp\n",
    "\n",
    "        if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "            file += \"\\n--preembed_nodes \\\\\"\n",
    "        elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "            split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "            file = \"\".join(split)\n",
    "\n",
    "        print(file)\n",
    "\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(file)\n",
    "\n",
    "        subprocess.run([\"sbatch\", filename])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results/5e-06-8-clip/winoground.log\n",
      "#SBATCH --error results/5e-06-8-clip/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 5e-06-8-clip \\\n",
      "Submitted batch job 2514034\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results/1e-06-8-clip/winoground.log\n",
      "#SBATCH --error results/1e-06-8-clip/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 1e-06-8-clip \\\n",
      "Submitted batch job 2514035\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=winoground\n",
      "#SBATCH --output results/1e-05-8-clip/winoground.log\n",
      "#SBATCH --error results/1e-05-8-clip/winoground.log\n",
      "#SBATCH --time=05:00:00\n",
      "#SBATCH --gres=gpu:rtxa5000:1\n",
      "#SBATCH --qos=scavenger\n",
      "#SBATCH --account=scavenger\n",
      "#SBATCH --partition=scavenger\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --mem=16G\n",
      "\n",
      "python3 winoground_eval.py \\\n",
      "--projection_dim 512 \\\n",
      "--image_encoder clip \\\n",
      "--text_encoder clip \\\n",
      "--num_layers 8 \\\n",
      "--exp_name 1e-05-8-clip \\\n",
      "Submitted batch job 2514036\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "\n",
    "\n",
    "file = \"\"\n",
    "filename = f\"run_winoground.sh\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    file = f.read()\n",
    "\n",
    "exps = [\n",
    "    # 'clip32-clip32_baseline',\n",
    "    # '1e-06-clip-clip_baseline',\n",
    "    # '5e-06-clip-clip_baseline',\n",
    "    # '1e-05-clip-clip_baseline',\n",
    "    # '4-clip',\n",
    "    # '4-clip_preembed',\n",
    "    # '6-clip',\n",
    "    # '6-clip_preembed',\n",
    "    # '8-clip',\n",
    "    # '8-clip_preembed',\n",
    "    # '5e-06-8-clip',\n",
    "    # '1e-06-8-clip',\n",
    "    # '1e-05-8-clip',\n",
    "    # '12-clip',\n",
    "    # '12-clip_preembed',\n",
    "]\n",
    "\n",
    "projection_dim = 512\n",
    "image_encoder = 'clip'\n",
    "text_encoder = 'clip'\n",
    "num_layers = 8\n",
    "\n",
    "for exp in exps:\n",
    "    result_dir = f'results/{exp}'\n",
    "\n",
    "    file = re.sub('--projection_dim .*', f\"--projection_dim {projection_dim} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--text_encoder .*', f\"--text_encoder {text_encoder} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--image_encoder .*', f\"--image_encoder {image_encoder} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--num_layers .*', f\"--num_layers {num_layers} \" + r\"\\\\\" , file)\n",
    "    file = re.sub('--exp_name .*', f\"--exp_name {exp} \" + r\"\\\\\" , file)\n",
    "\n",
    "    file = re.sub('--job-name=.*', f\"--job-name=winoground\", file)\n",
    "    file = re.sub('--output .*', f\"--output {result_dir}/winoground.log\", file)\n",
    "    file = re.sub('--error .*', f\"--error {result_dir}/winoground.log\", file)\n",
    "\n",
    "    \n",
    "    preembed_nodes = '_preembed' in exp\n",
    "\n",
    "    if preembed_nodes and \"--preembed_nodes \\\\\" not in file:\n",
    "        file += \"\\n--preembed_nodes \\\\\"\n",
    "    elif preembed_nodes == False and \"--preembed_nodes \\\\\" in file:\n",
    "        split = file.split(\"\\n--preembed_nodes \\\\\")\n",
    "        file = \"\".join(split)\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(file)\n",
    "\n",
    "    subprocess.run([\"sbatch\", filename])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
